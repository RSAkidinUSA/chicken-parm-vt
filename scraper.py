#!/usr/bin/python3
"""Simple script for scraping the  VT dining website for chicken parm day"""

# to install required packages, run:
# pip3 install beautifulsoup4 requests schedule

import requests
import schedule
import time
import sys

from bs4 import BeautifulSoup


DINING_URL = 'http://foodpro.dsa.vt.edu'
# Headers to treat as web browser
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'} 
SLACK_WEBHOOK_URLS = None



mem_db = {}
last_msg = ''

def init_settings():
    """ Initialize different interfaces to communicate over """
    global SLACK_WEBHOOK_URLS
    try:
        with open('slack.env', 'r') as f:
            SLACK_WEBHOOK_URLS = f.readlines()
    except (FileNotFoundError):
        pass


def post_updates(dates):
    """ Send updates to all initialized interfaces """
    msg = 'Chicken Parm will be served at Owens food court on the following date(s):\n'
    for i in dates:
        msg += i + '\n'
    msg += 'This message was generated by the chicken parm date checker (https://github.com/RSAkidinUSA/chicken-parm-vt)\n'
    # slack updates
    if (SLACK_WEBHOOK_URLS is not None):
        send_slack_msg(msg)

    # general print
    print(msg)


def send_slack_msg(msg):
    """Send a message to the enabled slack channel channel."""
    for url in SLACK_WEBHOOK_URLS:
        requests.post(url, json={'text': msg})




def get_menu():
    """Get a list of dates."""
    menu_dates = []
    html_doc = requests.get(DINING_URL + '/menus/search.aspx?Action=SEARCH&strCurKeywords=chicken+parm', headers=HEADERS).content
    soup = BeautifulSoup(html_doc, 'html.parser')
    menu_items = soup.find_all('li', class_='list-group-item menu_item')
    for item in menu_items:
        recipe_title =  list(item.find('a', class_='recipe_title'))[0]
        if 'Chicken Parmesan (no pasta)' in recipe_title:
            menu_dates.append(list(item.find('div', class_='col-lg-12 recipe_date_container'))[0].strip())
            
    if len(menu_dates):
        return menu_dates
    else:
        return None

# def get_messages(Start=None):
#     """Get a list of all messages since an optional start message"""
#     global last_msg
#     msgs = []
#     html_doc = requests.get(LEADERBOARD_URL, headers=HEADERS).text
#     soup = BeautifulSoup(html_doc, 'html.parser')
#     table = soup.find_all('table')[1]
#     table_body = table.find('tbody')
#     rows = table_body.find_all('tr')
#     for row in rows:
#         cells = row.find_all('td')
#         team = cells[1].text
#         event = cells[2].text
#         if ('Solved' in event):
#             msgs.append('%s %s' % (team, event))
#         else:
#             team += '\'' if team.endswith('s') else '\'s'
#             msgs.append('%s score updated' % (team,))
#         # break if last message reached
#         if (Start == None): 
#             break
#         elif (msgs[-1] == last_msg):
#             msgs = msgs[:-1]
#             break
#     if len(msgs) > 0:
#         last_msg = msgs[0]
#         return '\n'.join(msgs)
#     else:
#         return 'Retroactive updates to the scoreboard.\n'
    


if __name__ == '__main__':
    init_settings()
    cp_date = get_menu()
    if cp_date != None:
        post_updates(cp_date)
    else:
        print("Unable to determine the date for chicken parm :(")
    # schedule.every(3).minutes.do(check_for_updates)
    # while True:
    #     schedule.run_pending()
    #     time.sleep(1)
